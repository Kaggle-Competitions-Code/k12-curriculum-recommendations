{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabb03ee-e2be-4d32-8f7a-75d0cbe84ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58674556-f9cf-482f-bbf2-b69a8599818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATH:\n",
    "    model = '/root/autodl-nas/model/sentence-transformers/all-MiniLM-L6-v2_new_r1.1'\n",
    "    model_cpt = '/root/autodl-nas/model/f0r3/checkpoint-8708'\n",
    "    # input_dir = '/root/autodl-nas/data/k12'\n",
    "    input_dir = '/root/autodl-tmp/data/k12/cv_split_new/valid/fold_4'\n",
    "    \n",
    "    output_dir = '/root/autodl-tmp/data/k12/out'\n",
    "    cv_dir = '/root/autodl-tmp/data/k12/cv_split_new/valid/fold_4'\n",
    "    # pretrained_dir = '/root/autodl-nas/model/'\n",
    "    content_dir = os.path.join(input_dir, 'content.csv')\n",
    "    correlation_dir = os.path.join(input_dir, 'correlations.csv')\n",
    "    submission_dir = os.path.join(input_dir, 'sample_submission.csv')\n",
    "    topic_dir = os.path.join(input_dir, 'topics.csv')\n",
    "    \n",
    "    \n",
    "class CFG:\n",
    "    seed = 11\n",
    "    fold = 1\n",
    "    n_fold = 3\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d682abd-f04a-487e-9c30-9aad851e10d7",
   "metadata": {},
   "source": [
    "## Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b7b86e-1a5d-475b-b6db-218acec14691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level_features(df_topic, level_cols=['title']):\n",
    "    df_hier = df_topic[list(set(level_cols + ['id', 'parent', 'level', 'has_content']))]\n",
    "    highest_level = df_hier['level'].max()\n",
    "    \n",
    "    df_level = df_hier.query('level == 0').copy(deep=True)\n",
    "    level_list = list()\n",
    "    for col in level_cols:\n",
    "        df_level[f'{col}_level'] = df_level[f'{col}'].apply(lambda x: [x])\n",
    "\n",
    "    for i in tqdm(range(highest_level + 1)):\n",
    "        level_list.append(df_level[df_level['has_content']])\n",
    "        df_level_high = df_hier.query('level == @i+1')\n",
    "        df_level = df_level_high.merge(df_level, left_on='parent', right_on='id', suffixes=['', '_parent'], how='inner')\n",
    "        for col in level_cols:\n",
    "            df_level[f'{col}_level'] = df_level[f'{col}_level'] + df_level[f'{col}'].apply(lambda x: [x])\n",
    "        for col in df_level.columns:\n",
    "            if col.endswith('_parent'):\n",
    "                df_level.drop(columns=col, inplace=True)\n",
    "    df = pd.concat(level_list).reset_index(drop=True)\n",
    "    return df[list(set(['id'] + [f'{col}_level' for col in level_cols]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a9e16b7-0d49-4603-a1e1-9678beff122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_field(d):\n",
    "    title = list(filter(lambda x: pd.notna(x), d['title_level']))\n",
    "    title = ' of '.join(title[-1::-1])\n",
    "    title = 'No information' if title=='' else title\n",
    "    title = '[TITLE] ' + title + '. '\n",
    "    description = d['description'] if pd.notna(d['description']) else 'No information'\n",
    "    description = '[DESCRIPTION]' + description + '. '\n",
    "    field = title + description\n",
    "    return field\n",
    "\n",
    "def get_content_field(d):\n",
    "    title = d['title']\n",
    "    title = 'No information' if pd.isna(title) else title\n",
    "    title = '[TITLE] ' + title + '. '\n",
    "    description = d['description'] if pd.notna(d['description']) else 'No information'\n",
    "    description = '[DESCRIPTION]' + description + '. '\n",
    "    kind = '[' + d['kind'] + '] '\n",
    "    field = kind + title + description\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f05127c-7b3c-4898-a13d-8860aa46d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_language_match(path, mode='train'):\n",
    "    topic = pd.read_csv(path.topic_dir)[['id', 'language']]\n",
    "    content = pd.read_csv(path.content_dir)[['id', 'language']]\n",
    "    if mode == 'train':\n",
    "        corr = pd.read_csv(path.correlation_dir)\n",
    "    elif mode == 'valid':\n",
    "        corr = pd.read_csv(path.submission_dir)\n",
    "    \n",
    "    topic = topic.merge(corr, left_on='id', right_on='topic_id', how='right')[['id', 'language']]\n",
    "    match_dict = {}\n",
    "    for language in topic['language'].unique():\n",
    "        match_dict[language] = (topic.query('language==@language')[['id']], content.query('language==@language')[['id']])\n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e466c85c-a08a-43ac-880e-e968453a169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_match_features(topic, content, path):\n",
    "    df_topic = pd.read_csv(path.topic_dir)\n",
    "    df_content = pd.read_csv(path.content_dir)\n",
    "    level = get_level_features(df_topic)\n",
    "    df_topic = df_topic.merge(level, on='id', how='right')\n",
    "    df_topic['field'] = df_topic.apply(lambda x: get_topic_field(x), axis=1)\n",
    "    df_content['field'] = df_content.apply(lambda x: get_content_field(x), axis=1)\n",
    "    topic = topic[['id']].merge(df_topic[['id', 'field']], on='id', how='left')\n",
    "    content = content[['id']].merge(df_content[['id', 'field']], on='id', how='left')\n",
    "    return topic, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab94b55-ec29-4859-84cf-aae02c197399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 s, sys: 1.08 s, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_content_match = prepare_language_match(PATH, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d967897c-6328-4508-a449-409f27d86aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\t - topics: 3272\t - contents: 65939\n",
      "es\t - topics: 1297\t - contents: 30844\n",
      "gu\t - topics: 85\t - contents: 3677\n",
      "pt\t - topics: 43\t - contents: 10435\n",
      "hi\t - topics: 76\t - contents: 4042\n",
      "fr\t - topics: 79\t - contents: 10682\n",
      "bn\t - topics: 83\t - contents: 2513\n",
      "fil\t - topics: 38\t - contents: 516\n",
      "sw\t - topics: 17\t - contents: 1447\n",
      "as\t - topics: 10\t - contents: 641\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "for lang in topic_content_match.keys():\n",
    "    print(f'{lang}\\t - topics: {len(topic_content_match[lang][0])}\\t - contents: {len(topic_content_match[lang][1])}')\n",
    "#     topic, content = topic_content_match[lang]\n",
    "#     topic, content = prepare_match_features(topic, content, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938fd06-20e7-4575-a5e2-5444486a1525",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calc Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "733362a1-5df4-4895-8063-92e17141245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "CPT_PATH = PATH.model_cpt\n",
    "MODEL_PATH = PATH.model\n",
    "OUTPUT_PATH = os.path.join(PATH.cv_dir)\n",
    "N_NEIGHBOR = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468cf7f2-a99f-424c-9e38-69d436c58d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, label_name=\"\") -> None:\n",
    "        super().__init__()\n",
    "        self.data = df[label_name].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[index]\n",
    "        inputs = self.tokenizer(\n",
    "                text, \n",
    "                add_special_tokens = True,\n",
    "                truncation='longest_first',\n",
    "                max_length = 128,\n",
    "                padding = 'max_length',\n",
    "                return_attention_mask = True,\n",
    "                return_tensors = 'pt',\n",
    "        )\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d92794b6-f21c-470f-b665-fe2218beb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convert2Embed(object):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "        self.model = AutoModel.from_pretrained(CPT_PATH).cuda()\n",
    "\n",
    "    def convert2embeddind(self, df, label_name=\"\"):\n",
    "        embed: list = []\n",
    "        dataset = PlainDataset(df, tokenizer=self.tokenizer, label_name=label_name)\n",
    "        dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=32)\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                embeddings = self.model(**batch, output_hidden_states=True, return_dict=True).pooler_output\n",
    "                embed.append(embeddings.cpu().clone().detach().numpy())\n",
    "        embed = np.concatenate(embed, axis=0)\n",
    "        return embed\n",
    "\n",
    "    def get_embed(self):\n",
    "        for lang in topic_content_match.keys():\n",
    "            #\n",
    "            # topic, content = topic_content_match[lang]\n",
    "            # topic, content = prepare_match_features(topic, content, PATH)\n",
    "            # topic_path = os.path.join(OUTPUT_PATH, \"valid\", f\"topic_{lang}.pqt\")\n",
    "            # content_path = os.path.join(OUTPUT_PATH, \"valid\", f\"content_{lang}.pqt\")\n",
    "            # topic.to_parquet(topic_path)\n",
    "            # content.to_parquet(content_path)\n",
    "            #\n",
    "            \n",
    "            for t in [\"content\", \"topic\"]:\n",
    "                path = os.path.join(OUTPUT_PATH, \"valid\", f\"{t}_{lang}.pqt\")\n",
    "                df = pd.read_parquet(path)\n",
    "                embed = self.convert2embeddind(df, label_name=f\"field\")\n",
    "                np.save(path.replace(\".pqt\", \".npy\"), embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f04215-9027-4408-9deb-45df9f232abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f08b9ef-56fe-44bd-8f61-1f54f6d51c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid():\n",
    "#     with open(os.path.join(OUTPUT_PATH, \"valid\", \"language.txt\"), \"r\") as f:\n",
    "#         valid_language = f.read().splitlines()\n",
    "    recall_amount = 0\n",
    "    recall_amount_total = 0\n",
    "    recall_num = 0\n",
    "    recall_total = {}\n",
    "    f2_sum = 0\n",
    "    df_list = []\n",
    "    global df_pred_all\n",
    "    for lang in topic_content_match.keys():\n",
    "        ## debug\n",
    "        # global df_pred, df_correlations\n",
    "        global df_pred\n",
    "        content_path = os.path.join(OUTPUT_PATH, \"valid\", f\"content_{lang}.npy\")\n",
    "        topics_path = os.path.join(OUTPUT_PATH, \"valid\", f\"topic_{lang}.npy\")\n",
    "        correlations_path = PATH.submission_dir\n",
    "        content_array = np.load(content_path)\n",
    "        topics_array = np.load(topics_path)\n",
    "        model = NearestNeighbors(n_neighbors=N_NEIGHBOR, metric=\"cosine\")\n",
    "        model.fit(content_array)\n",
    "        d, r = model.kneighbors(topics_array)\n",
    "        df_content = pd.read_parquet(content_path.replace(\".npy\", \".pqt\"))\n",
    "        df_topics = pd.read_parquet(topics_path.replace(\".npy\", \".pqt\"))\n",
    "        df_correlations = pd.read_csv(correlations_path).astype({\"topic_id\": str})\n",
    "        \n",
    "        pred = {\"topic_id\": [], \"content_ids\": [], 'dists': []}\n",
    "        for i in range(len(df_topics)):\n",
    "            r_t = r[i]\n",
    "            tmp = []\n",
    "            for c in r_t:\n",
    "                content_id = df_content.iloc[c][\"id\"]\n",
    "                tmp.append(content_id)\n",
    "            topics_id = df_topics.iloc[i][\"id\"]\n",
    "            pred[\"topic_id\"].append(topics_id)\n",
    "            pred[\"content_ids\"].append(tmp)\n",
    "            pred['dists'].append(d[i])\n",
    "        \n",
    "        df_pred = pd.DataFrame(pred).astype({\"topic_id\": str})\n",
    "        \n",
    "        df_correlations['content_ids'] = df_correlations['content_ids'].apply(lambda x: list(x.split()))\n",
    "        df_pred = df_pred.merge(df_correlations, on='topic_id', how='left', suffixes=['_pred', '_true'])\n",
    "        df_pred['num'] = df_pred.apply(lambda x: len(x['content_ids_true']), axis=1)\n",
    "        df_pred['hit'] = df_pred.apply(lambda x: len(set(x['content_ids_true']).intersection(x['content_ids_pred'])), axis=1)\n",
    "        df_pred['recall'] = df_pred.apply(lambda x: x['hit'] / len(x['content_ids_true']), axis=1)\n",
    "        df_pred['precision'] = df_pred.apply(lambda x: x['hit'] / len(x['content_ids_pred']), axis=1)\n",
    "        df_pred['f2'] = 5*df_pred['precision']*df_pred['recall']/(4*df_pred['precision']+df_pred['recall'])\n",
    "        recall = df_pred['recall'].mean()\n",
    "        recall_total[lang] = recall\n",
    "        recall_num += len(df_pred)\n",
    "        recall_amount += df_pred['recall'].sum()\n",
    "        recall_amount_total += df_pred['hit'].sum()/df_pred['num'].sum() * len(df_pred)\n",
    "        f2_sum += df_pred['f2'].sum()\n",
    "        df_list.append(df_pred)\n",
    "        print(f\"{lang}: {df_pred['hit'].sum()/df_pred['num'].sum()} - f2: {df_pred['f2'].sum()/len(df_pred)}\")\n",
    "        \n",
    "    df_pred_all = pd.concat(df_list)\n",
    "    print(f\"Recall: total - {recall_amount_total/recall_num} line average - {recall_amount/recall_num} - f2 - {f2_sum/recall_num}\")\n",
    "    print(f\"----------------Details----------------\")\n",
    "    for k, v in recall_total.items():\n",
    "        print(f\"Recall for language {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57f2c62-3a2e-437c-92f0-f25c70c4ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-nas/model/f0r3/checkpoint-4976 were not used when initializing BertModel: ['lm_head.transform.LayerNorm.weight', 'lm_head.transform.dense.weight', 'mlp.dense.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.transform.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'mlp.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /root/autodl-nas/model/f0r3/checkpoint-4976 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.1 s, sys: 1min 12s, total: 2min 7s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "P = Convert2Embed()\n",
    "P.get_embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4114439-f87c-40cd-88c7-a4e5b2f715cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_by_thresh(df, thresh, n_default=1):\n",
    "    pred_by_thresh = list()\n",
    "    for i, d in enumerate(df['dists']):\n",
    "        if d<=thresh:\n",
    "            pred_by_thresh.append(df['content_ids_pred'][i])\n",
    "    if not pred_by_thresh:\n",
    "        pred_by_thresh = df['content_ids_pred'][:n_default]\n",
    "    return pred_by_thresh\n",
    "\n",
    "def calculate_f2(df_pred_all, true_label='content_ids_true', pred_label='pred_by_thresh') -> int:\n",
    "    df_pred_all['hit'] = df_pred_all.apply(lambda x: len(set(x[pred_label]).intersection(x[true_label])), axis=1)\n",
    "    df_pred_all['recall'] = df_pred_all.apply(lambda x: x['hit']/len(x[true_label]), axis=1)\n",
    "    df_pred_all['precision'] = df_pred_all.apply(lambda x: x['hit']/len(x[pred_label]), axis=1)\n",
    "    df_pred_all['f2'] = (5*df_pred_all['precision']*df_pred_all['recall']/(4*df_pred_all['precision']+df_pred_all['recall'])).fillna(0)\n",
    "    return df_pred_all['f2'].mean()\n",
    "\n",
    "def optimize_f2(df_pred_all, init_thresh=0.2, init_step=0.01) -> int:\n",
    "    thresh = init_thresh\n",
    "    df_pred_all['pred_by_thresh'] = df_pred_all.apply(lambda x: get_pred_by_thresh(x, 0.2), axis=1)\n",
    "    f2 = calculate_f2(df_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "373e7312-ef84-4080-a662-0efdba71d960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_0012a45fa09c</td>\n",
       "      <td>c_dde078b8ea7a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001bcbb22694</td>\n",
       "      <td>c_1d9dfc709413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00260f878951</td>\n",
       "      <td>c_86f126d7f1f8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003e944a4758</td>\n",
       "      <td>c_8f6966ad85f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00535b89fd1d</td>\n",
       "      <td>c_189799d6b9a3 c_33e862f552f5 c_4f1702d3ffce c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>t_ffba5459a977</td>\n",
       "      <td>c_04a421dba8aa c_787a7a2e7217 c_a46e0ec1377b c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>t_ffc6ba0459d6</td>\n",
       "      <td>c_877d4e87d0e8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>t_ffc71a181765</td>\n",
       "      <td>c_d7be46af5e2b c_ea92fdd9899a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>t_ffdc013937fc</td>\n",
       "      <td>c_c27c5e711e25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>t_fff51448598c</td>\n",
       "      <td>c_054e15d2ff3f c_113437812aa0 c_9c817a2bcb3c c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic_id                                        content_ids\n",
       "0     t_0012a45fa09c                                     c_dde078b8ea7a\n",
       "1     t_001bcbb22694                                     c_1d9dfc709413\n",
       "2     t_00260f878951                                     c_86f126d7f1f8\n",
       "3     t_003e944a4758                                     c_8f6966ad85f6\n",
       "4     t_00535b89fd1d  c_189799d6b9a3 c_33e862f552f5 c_4f1702d3ffce c...\n",
       "...              ...                                                ...\n",
       "4995  t_ffba5459a977  c_04a421dba8aa c_787a7a2e7217 c_a46e0ec1377b c...\n",
       "4996  t_ffc6ba0459d6                                     c_877d4e87d0e8\n",
       "4997  t_ffc71a181765                      c_d7be46af5e2b c_ea92fdd9899a\n",
       "4998  t_ffdc013937fc                                     c_c27c5e711e25\n",
       "4999  t_fff51448598c  c_054e15d2ff3f c_113437812aa0 c_9c817a2bcb3c c...\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(PATH.submission_dir).astype({\"topic_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa279c14-960f-4f13-af11-c30671b1a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 275 383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66ae30f5-7082-46dc-98f2-f0ce7ecc6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred_all['pred_by_thresh'] = df_pred_all.apply(lambda x: get_pred_by_thresh(x, 0.4), axis=1)\n",
    "# print(calculate_f2(df_pred_all))\n",
    "\n",
    "# df_pred_all = df_pred_all[['topic_id', 'content_ids_pred', 'dists', 'content_ids_true']]\n",
    "# # df_pred_all['labels'] = df_pred_all.apply(lambda x: label_pred(x), axis=1)\n",
    "# for i in range(170, 450, 2):\n",
    "#     thresh = i/1000\n",
    "#     df_pred_all['pred_by_thresh'] = df_pred_all.apply(lambda x: get_pred_by_thresh(x, thresh, 3), axis=1)\n",
    "#     f2 = calculate_f2(df_pred_all)\n",
    "#     print(i, f2)\n",
    "\n",
    "# df_pred_all.explode(['content_ids_pred', 'dists', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029907ba-84de-42ae-ba39-b87562768b32",
   "metadata": {},
   "source": [
    "170 0.4024688386835773\n",
    "172 0.4031549520762678\n",
    "174 0.40409479083512645\n",
    "176 0.40498780130113327\n",
    "178 0.4056221467042033\n",
    "180 0.40624726560527924\n",
    "182 0.40721841030008704\n",
    "184 0.409052690435736\n",
    "186 0.41030785013923904\n",
    "188 0.4105493930238\n",
    "190 0.4121692194096475\n",
    "192 0.4132842857948191\n",
    "194 0.4144896801795744\n",
    "196 0.41615635613829677\n",
    "198 0.41766006453443766\n",
    "200 0.41965067582784593\n",
    "202 0.4202251120409235\n",
    "204 0.42037800850695833\n",
    "206 0.4214418561517112\n",
    "208 0.4235262148368645\n",
    "210 0.42532777889037154\n",
    "212 0.42699839812736545\n",
    "214 0.42848119762586157\n",
    "216 0.43026228612064904\n",
    "218 0.43200040637419174\n",
    "220 0.4332824488732244\n",
    "222 0.43483586366382354\n",
    "224 0.4367978856794664\n",
    "226 0.43781717992134717\n",
    "228 0.4391767284118734\n",
    "230 0.44009180614394006\n",
    "232 0.4417736674332854\n",
    "234 0.4430857341640051\n",
    "236 0.44381462956587736\n",
    "238 0.44525578177706604\n",
    "240 0.4471523710828244\n",
    "242 0.44870426476357084\n",
    "244 0.4497284873353738\n",
    "246 0.45163057757041214\n",
    "248 0.4530941896947352\n",
    "250 0.4548706386758581\n",
    "252 0.45620181582970554\n",
    "254 0.45695022797459456\n",
    "256 0.4576392577793879\n",
    "258 0.4577774966032547\n",
    "260 0.45801281237339675\n",
    "262 0.45868644081494886\n",
    "264 0.458481439820201\n",
    "266 0.45903038240513294\n",
    "268 0.4595054445782289\n",
    "270 0.4594602890972266\n",
    "272 0.4594325829137616\n",
    "274 0.45987696587445226\n",
    "276 0.4602119501917246\n",
    "278 0.46098732313376983\n",
    "280 0.46121830781870066\n",
    "282 0.46157880182145566\n",
    "284 0.460916378887469\n",
    "286 0.46063599518269166\n",
    "288 0.46015462896328635\n",
    "290 0.46026819515777456\n",
    "292 0.46005084723586476\n",
    "294 0.45913039790317867\n",
    "296 0.45844901040602476\n",
    "298 0.45750240076191034\n",
    "300 0.45692206443176586\n",
    "302 0.45608328843132245\n",
    "304 0.4549603767536112\n",
    "306 0.45329443276876796\n",
    "308 0.4517214889907147\n",
    "310 0.45083376456284796\n",
    "312 0.44961959295741877\n",
    "314 0.448034045429716\n",
    "316 0.4461080456862716\n",
    "318 0.44414396537646245\n",
    "320 0.4425980612628054\n",
    "322 0.44092277734608776\n",
    "324 0.4389668410680323\n",
    "326 0.4367121022990652\n",
    "328 0.43420323722183946\n",
    "330 0.4315968321759618\n",
    "332 0.4294783204714232\n",
    "334 0.4271767339470532\n",
    "336 0.42463422374234044\n",
    "338 0.42189842384377607\n",
    "340 0.41922310125359186\n",
    "342 0.4163151008820663\n",
    "344 0.4132511312819868\n",
    "346 0.4100375863146136\n",
    "348 0.4068978474694664\n",
    "350 0.4041449159496747\n",
    "352 0.4010115542362085\n",
    "354 0.3977875787529075\n",
    "356 0.3948931385115175\n",
    "358 0.3913653717224516\n",
    "360 0.3877346850668936\n",
    "362 0.38452566672457694\n",
    "364 0.38094351006016375\n",
    "366 0.37740241893768\n",
    "368 0.3736814676972883\n",
    "370 0.36987613243759815\n",
    "372 0.36632612945386933\n",
    "374 0.36227639122395994\n",
    "376 0.35868013462650117\n",
    "378 0.35507737565132824\n",
    "380 0.3512169514101543\n",
    "382 0.3472301898209479\n",
    "384 0.343266006151315\n",
    "386 0.3389849776348872\n",
    "388 0.33505053612718283\n",
    "390 0.33077591982865007\n",
    "392 0.32659240791737504\n",
    "394 0.3223306480778996\n",
    "396 0.3180902050053218\n",
    "398 0.3139647617144388\n",
    "400 0.30977561550307586\n",
    "402 0.3056369682307033\n",
    "404 0.3015421054155209\n",
    "406 0.29711072715398107\n",
    "408 0.2929429504219797\n",
    "410 0.2888552872196978\n",
    "412 0.2845286862129868\n",
    "414 0.28014803099027047\n",
    "416 0.2759176750171542\n",
    "418 0.2719160264420336\n",
    "420 0.26765219196053575\n",
    "422 0.2634692270432641\n",
    "424 0.2592592306452557\n",
    "426 0.25531781926012703\n",
    "428 0.25119991693635824\n",
    "430 0.24713812191438406\n",
    "432 0.24296433979588497\n",
    "434 0.23907443839564776\n",
    "436 0.23522140710825673\n",
    "438 0.2312847831007713\n",
    "440 0.2273921890591881\n",
    "442 0.22357551167977419\n",
    "444 0.2195538619615006\n",
    "​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae55ada-17dd-4be9-b840-b2fa7022824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 0.4559003806697206 - f2: 0.4833704268895825\n",
      "es: 0.35022450288646567 - f2: 0.21913522024447865\n",
      "gu: 0.2724252491694352 - f2: 0.23763295528001407\n",
      "pt: 0.44 - f2: 0.42079420714530763\n",
      "hi: 0.3786127167630058 - f2: 0.3801770600084109\n",
      "fr: 0.35795454545454547 - f2: 0.40121214750673617\n",
      "bn: 0.3130841121495327 - f2: 0.2769304323521191\n",
      "fil: 0.5663716814159292 - f2: 0.5758738277919866\n",
      "sw: 0.21428571428571427 - f2: 0.23828981097132673\n",
      "as: 0.13043478260869565 - f2: 0.12142857142857144\n",
      "Recall: total - 0.41950633154210637 line average - 0.5303243860248875 - f2 - 0.40296444592032865\n",
      "----------------Details----------------\n",
      "Recall for language en: 0.6203178383818506\n",
      "Recall for language es: 0.32840179181736623\n",
      "Recall for language gu: 0.2917647058823529\n",
      "Recall for language pt: 0.5617571059431524\n",
      "Recall for language hi: 0.4580357142857143\n",
      "Recall for language fr: 0.46225457962241284\n",
      "Recall for language bn: 0.4523001095290253\n",
      "Recall for language fil: 0.812155388471178\n",
      "Recall for language sw: 0.31280255692020403\n",
      "Recall for language as: 0.2\n",
      "CPU times: user 9.29 s, sys: 13.5 s, total: 22.8 s\n",
      "Wall time: 6.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 6\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02d0ef0a-0c8c-44c1-84cb-b821e8e75ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 0.4160913607329505 - f2: 0.47876447655758103\n",
      "es: 0.3197562540089801 - f2: 0.21829933678309532\n",
      "gu: 0.2425249169435216 - f2: 0.22790988065019624\n",
      "pt: 0.4177777777777778 - f2: 0.42992759881479914\n",
      "hi: 0.3439306358381503 - f2: 0.3616690479796676\n",
      "fr: 0.32386363636363635 - f2: 0.3909319033061913\n",
      "bn: 0.29439252336448596 - f2: 0.2914584729633973\n",
      "fil: 0.5575221238938053 - f2: 0.6098800372847561\n",
      "sw: 0.17857142857142858 - f2: 0.21187478274665966\n",
      "as: 0.13043478260869565 - f2: 0.13247863247863248\n",
      "Recall: total - 0.38328765880159 line average - 0.49849305861456544 - f2 - 0.39963489080405784\n",
      "----------------Details----------------\n",
      "Recall for language en: 0.5842774428277642\n",
      "Recall for language es: 0.3050552933744915\n",
      "Recall for language gu: 0.26640522875816997\n",
      "Recall for language pt: 0.5471576227390181\n",
      "Recall for language hi: 0.4065737259816207\n",
      "Recall for language fr: 0.43456987704940053\n",
      "Recall for language bn: 0.4427710843373494\n",
      "Recall for language fil: 0.7989974937343358\n",
      "Recall for language sw: 0.2669431875314228\n",
      "Recall for language as: 0.2\n",
      "CPU times: user 9.17 s, sys: 13.1 s, total: 22.2 s\n",
      "Wall time: 6.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 5\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55467b6b-1272-4d99-861d-8f4903f051f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 0.5608103748628944 - f2: 0.46272820117882496\n",
      "es: 0.4448364336112893 - f2: 0.20802799228846244\n",
      "gu: 0.3488372093023256 - f2: 0.24870841676919606\n",
      "pt: 0.5555555555555556 - f2: 0.43300800312186266\n",
      "hi: 0.476878612716763 - f2: 0.38613192168729654\n",
      "fr: 0.44507575757575757 - f2: 0.4147858252609478\n",
      "bn: 0.4439252336448598 - f2: 0.28472678330934886\n",
      "fil: 0.5929203539823009 - f2: 0.4612155794482969\n",
      "sw: 0.3125 - f2: 0.2741075286584825\n",
      "as: 0.17391304347826086 - f2: 0.11904761904761904\n",
      "Recall: total - 0.5206593220636823 line average - 0.6067739233780436 - f2 - 0.3865482930540207\n",
      "----------------Details----------------\n",
      "Recall for language en: 0.7038321016058207\n",
      "Recall for language es: 0.3824609009169534\n",
      "Recall for language gu: 0.37594771241830066\n",
      "Recall for language pt: 0.6714285714285715\n",
      "Recall for language hi: 0.5526733500417711\n",
      "Recall for language fr: 0.5476154750354304\n",
      "Recall for language bn: 0.5780941949616649\n",
      "Recall for language fil: 0.8304577232555072\n",
      "Recall for language sw: 0.39695288371758963\n",
      "Recall for language as: 0.25\n",
      "CPU times: user 10.3 s, sys: 13.9 s, total: 24.2 s\n",
      "Wall time: 7.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 10\n",
    "valid() # Recall: total - 0.5210813346754415 line average - 0.6065079786898661 - f2 - 0.3860233037535843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4828ea18-f47e-4442-82aa-1bdd9b403e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 0.6777211432995677 - f2: 0.38085379935036406\n",
      "es: 0.5657472738935215 - f2: 0.17824560676119847\n",
      "gu: 0.42524916943521596 - f2: 0.21000445632798578\n",
      "pt: 0.6577777777777778 - f2: 0.3787142947112167\n",
      "hi: 0.5982658959537572 - f2: 0.3362397030643935\n",
      "fr: 0.571969696969697 - f2: 0.39182906401298795\n",
      "bn: 0.6495327102803738 - f2: 0.2591635481319216\n",
      "fil: 0.6814159292035398 - f2: 0.32920013100934165\n",
      "sw: 0.5089285714285714 - f2: 0.3084005455328985\n",
      "as: 0.391304347826087 - f2: 0.15610119047619048\n",
      "Recall: total - 0.6397464165142329 line average - 0.6983979313213164 - f2 - 0.32176119820923443\n",
      "----------------Details----------------\n",
      "Recall for language en: 0.7888184412213224\n",
      "Recall for language es: 0.48446455775869807\n",
      "Recall for language gu: 0.4392623716153128\n",
      "Recall for language pt: 0.7819029162052417\n",
      "Recall for language hi: 0.6489087301587301\n",
      "Recall for language fr: 0.6703501328929474\n",
      "Recall for language bn: 0.7444786137557221\n",
      "Recall for language fil: 0.8787033372905949\n",
      "Recall for language sw: 0.5691499676793794\n",
      "Recall for language as: 0.4533333333333333\n",
      "CPU times: user 12.8 s, sys: 14.4 s, total: 27.1 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 20\n",
    "valid() # Recall: total - 0.6391622861430047 line average - 0.6950282194812909 - f2 - 0.32047399962118284\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e994d-cc6f-4343-9444-fd0a27cf998c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c004a5f-6bf1-4cb1-b2b9-95f758935e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 0.7930189044454481 - f2: 0.2409580600065519\n",
      "es: 0.6706221937139192 - f2: 0.11463885439010225\n",
      "gu: 0.5249169435215947 - f2: 0.13933127963978473\n",
      "pt: 0.7511111111111111 - f2: 0.25180457217313895\n",
      "hi: 0.7427745664739884 - f2: 0.2270816321019149\n",
      "fr: 0.6988636363636364 - f2: 0.28224314086587227\n",
      "bn: 0.8598130841121495 - f2: 0.17045192995076275\n",
      "fil: 0.7964601769911505 - f2: 0.18613522878495656\n",
      "sw: 0.7232142857142857 - f2: 0.25994204921657704\n",
      "as: 0.6956521739130435 - f2: 0.13098975345916392\n",
      "Recall: total - 0.7548025580395137 line average - 0.7866962783619373 - f2 - 0.20525541905547828\n",
      "----------------Details----------------\n",
      "Recall for language en: 0.8624029975351576\n",
      "Recall for language es: 0.6012772964358071\n",
      "Recall for language gu: 0.5270028011204482\n",
      "Recall for language pt: 0.8447120708748614\n",
      "Recall for language hi: 0.7577798663324978\n",
      "Recall for language fr: 0.7857700484617834\n",
      "Recall for language bn: 0.9028154576347346\n",
      "Recall for language fil: 0.9396121883656509\n",
      "Recall for language sw: 0.8010719672484378\n",
      "Recall for language as: 0.6799999999999999\n",
      "CPU times: user 19.8 s, sys: 15.3 s, total: 35.1 s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 50 # 0.7559275033172171 line average - 0.7874367900873033 - f2 - 0.20525149868153938\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50cde0c9-1d89-4aa9-adf1-6c29c4bcecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 0.855539067036583 - f2: 0.1522766517385763\n",
      "es: 0.7517639512508018 - f2: 0.07455100386142097\n",
      "gu: 0.5913621262458472 - f2: 0.08951118714790071\n",
      "pt: 0.8533333333333334 - f2: 0.1722736989288002\n",
      "hi: 0.8352601156069365 - f2: 0.14956109219285033\n",
      "fr: 0.7878787878787878 - f2: 0.19300351114150155\n",
      "bn: 0.9299065420560748 - f2: 0.10320044239721249\n",
      "fil: 0.7964601769911505 - f2: 0.10352226326069704\n",
      "sw: 0.875 - f2: 0.19115635721928978\n",
      "as: 0.9565217391304348 - f2: 0.09890109890109891\n",
      "Recall: total - 0.8237861852632786 line average - 0.8478493721424663 - f2 - 0.1306620297259688\n",
      "----------------Details----------------\n",
      "Recall for language en: 0.9003655397521046\n",
      "Recall for language es: 0.7206168320822046\n",
      "Recall for language gu: 0.5988982259570494\n",
      "Recall for language pt: 0.9080472499077151\n",
      "Recall for language hi: 0.8248955722639933\n",
      "Recall for language fr: 0.8420515941960468\n",
      "Recall for language bn: 0.9498174516246805\n",
      "Recall for language fil: 0.9396121883656509\n",
      "Recall for language sw: 0.9061265531853767\n",
      "Recall for language as: 0.95\n",
      "CPU times: user 32.1 s, sys: 15.5 s, total: 47.6 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 100\n",
    "valid() # 0.8259401867088655 line average - 0.8492008962245811 - f2 - 0.13077495168822426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b6c6674-9d0d-4cd1-bc71-f81fa2cd014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 0.9058003742176914 - f2: 0.09010325178925496\n",
      "es: 0.8277742142398974 - f2: 0.04475314405750251\n",
      "gu: 0.6411960132890365 - f2: 0.052337540522346473\n",
      "pt: 0.9111111111111111 - f2: 0.1035415025895308\n",
      "hi: 0.9017341040462428 - f2: 0.08964752868743232\n",
      "fr: 0.8333333333333334 - f2: 0.11687854124602665\n",
      "bn: 0.9719626168224299 - f2: 0.057759794506208405\n",
      "fil: 0.9292035398230089 - f2: 0.06261366114090322\n",
      "sw: 0.9821428571428571 - f2: 0.12363072381358618\n",
      "as: 0.9565217391304348 - f2: 0.05205115592879189\n",
      "Recall: total - 0.8815381644259791 line average - 0.8968322742628836 - f2 - 0.07752117522458835\n",
      "----------------Details----------------\n",
      "Recall for language en: 0.9345313642413996\n",
      "Recall for language es: 0.8091058050500656\n",
      "Recall for language gu: 0.6790756302521008\n",
      "Recall for language pt: 0.9478036175710594\n",
      "Recall for language hi: 0.8687238930659984\n",
      "Recall for language fr: 0.8750671878519979\n",
      "Recall for language bn: 0.9728915662650602\n",
      "Recall for language fil: 0.9759002770083102\n",
      "Recall for language sw: 0.9411764705882353\n",
      "Recall for language as: 0.95\n",
      "CPU times: user 55.6 s, sys: 15.9 s, total: 1min 11s\n",
      "Wall time: 52.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 200\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d97fe-c8e3-409d-8d08-7f77201ef940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8d6cc0-3a57-4dae-b7e8-33e40c87959e",
   "metadata": {},
   "source": [
    "shuffle?\n",
    "\n",
    "groupby lang shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6a701ad5-deed-4cad-815c-2cbf3b57ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          755Gi        68Gi        17Gi       4.0Gi       670Gi       678Gi\n",
      "Swap:         1.9Gi        37Mi       1.9Gi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610ea9f-5532-4bca-af7e-15d5a8bc2240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
