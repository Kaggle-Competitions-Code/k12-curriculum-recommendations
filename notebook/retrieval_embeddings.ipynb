{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fabb03ee-e2be-4d32-8f7a-75d0cbe84ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from torch.utils.data import DataLoader, Dataset, SequentialSampler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58674556-f9cf-482f-bbf2-b69a8599818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PATH:\n",
    "    # epoch 34668\n",
    "    model = '/root/autodl-nas/model/sentence-transformers/all-MiniLM-L6-v2_new_r1.1'\n",
    "    model_cpt = '/root/autodl-nas/model/r1_13/checkpoint-9738'\n",
    "    # input_dir = '/root/autodl-nas/data/k12'\n",
    "    input_dir = '/root/autodl-nas/data/k12/cv_data/fold_0'\n",
    "    \n",
    "    output_dir = '/root/autodl-nas/data/k12/out'\n",
    "    cv_dir = '/root/autodl-nas/data/k12/cv_data'\n",
    "    pretrained_dir = '/root/autodl-nas/model/'\n",
    "    content_dir = os.path.join(input_dir, 'content.csv')\n",
    "    correlation_dir = os.path.join(input_dir, 'correlations.csv')\n",
    "    submission_dir = os.path.join(input_dir, 'sample_submission.csv')\n",
    "    topic_dir = os.path.join(input_dir, 'topics.csv')\n",
    "    \n",
    "    \n",
    "class CFG:\n",
    "    seed = 11\n",
    "    fold = 0\n",
    "    n_fold = 3\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    # cpt = '/root/autodl-nas/model/checkpoint-34668/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d682abd-f04a-487e-9c30-9aad851e10d7",
   "metadata": {},
   "source": [
    "## Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72b7b86e-1a5d-475b-b6db-218acec14691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level_features(df_topic, level_cols=['title']):\n",
    "    df_hier = df_topic[list(set(level_cols + ['id', 'parent', 'level', 'has_content']))]\n",
    "    highest_level = df_hier['level'].max()\n",
    "    \n",
    "    df_level = df_hier.query('level == 0').copy(deep=True)\n",
    "    level_list = list()\n",
    "    for col in level_cols:\n",
    "        df_level[f'{col}_level'] = df_level[f'{col}'].apply(lambda x: [x])\n",
    "\n",
    "    for i in tqdm(range(highest_level + 1)):\n",
    "        level_list.append(df_level[df_level['has_content']])\n",
    "        df_level_high = df_hier.query('level == @i+1')\n",
    "        df_level = df_level_high.merge(df_level, left_on='parent', right_on='id', suffixes=['', '_parent'], how='inner')\n",
    "        for col in level_cols:\n",
    "            df_level[f'{col}_level'] = df_level[f'{col}_level'] + df_level[f'{col}'].apply(lambda x: [x])\n",
    "        for col in df_level.columns:\n",
    "            if col.endswith('_parent'):\n",
    "                df_level.drop(columns=col, inplace=True)\n",
    "    df = pd.concat(level_list).reset_index(drop=True)\n",
    "    return df[list(set(['id'] + [f'{col}_level' for col in level_cols]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a9e16b7-0d49-4603-a1e1-9678beff122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_field(d):\n",
    "    title = list(filter(lambda x: pd.notna(x), d['title_level']))\n",
    "    title = ' of '.join(title[-1::-1])\n",
    "    title = 'No information' if title=='' else title\n",
    "    title = '[TITLE] ' + title + '. '\n",
    "    description = d['description'] if pd.notna(d['description']) else 'No information'\n",
    "    description = '[DESCRIPTION]' + description + '. '\n",
    "    field = title + description\n",
    "    return field\n",
    "\n",
    "def get_content_field(d):\n",
    "    title = d['title']\n",
    "    title = 'No information' if pd.isna(title) else title\n",
    "    title = '[TITLE] ' + title + '. '\n",
    "    description = d['description'] if pd.notna(d['description']) else 'No information'\n",
    "    description = '[DESCRIPTION]' + description + '. '\n",
    "    kind = '[' + d['kind'] + '] '\n",
    "    field = kind + title + description\n",
    "    return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f05127c-7b3c-4898-a13d-8860aa46d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_language_match(path, mode='train'):\n",
    "    topic = pd.read_csv(path.topic_dir)[['id', 'language']]\n",
    "    content = pd.read_csv(path.content_dir)[['id', 'language']]\n",
    "    if mode == 'train':\n",
    "        corr = pd.read_csv(path.correlation_dir)\n",
    "    elif mode == 'valid':\n",
    "        corr = pd.read_csv(path.submission_dir)\n",
    "    \n",
    "    topic = topic.merge(corr, left_on='id', right_on='topic_id', how='right')[['id', 'language']]\n",
    "    match_dict = {}\n",
    "    for language in topic['language'].unique():\n",
    "        match_dict[language] = (topic.query('language==@language')[['id']], content.query('language==@language')[['id']])\n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e466c85c-a08a-43ac-880e-e968453a169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_match_features(topic, content, path):\n",
    "    df_topic = pd.read_csv(path.topic_dir)\n",
    "    df_content = pd.read_csv(path.content_dir)\n",
    "    level = get_level_features(df_topic)\n",
    "    df_topic = df_topic.merge(level, on='id', how='right')\n",
    "    df_topic['field'] = df_topic.apply(lambda x: get_topic_field(x), axis=1)\n",
    "    df_content['field'] = df_content.apply(lambda x: get_content_field(x), axis=1)\n",
    "    topic = topic[['id']].merge(df_topic[['id', 'field']], on='id', how='left')\n",
    "    content = content[['id']].merge(df_content[['id', 'field']], on='id', how='left')\n",
    "    return topic, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fab94b55-ec29-4859-84cf-aae02c197399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 1.41 s, total: 11.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_content_match = prepare_language_match(PATH, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d967897c-6328-4508-a449-409f27d86aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu\t - topics: 131\t - contents: 3677\n",
      "en\t - topics: 5373\t - contents: 65939\n",
      "es\t - topics: 2189\t - contents: 30844\n",
      "fr\t - topics: 111\t - contents: 10682\n",
      "hi\t - topics: 132\t - contents: 4042\n",
      "fil\t - topics: 83\t - contents: 516\n",
      "pt\t - topics: 76\t - contents: 10435\n",
      "bn\t - topics: 191\t - contents: 2513\n",
      "as\t - topics: 18\t - contents: 641\n",
      "sw\t - topics: 31\t - contents: 1447\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "for lang in topic_content_match.keys():\n",
    "    print(f'{lang}\\t - topics: {len(topic_content_match[lang][0])}\\t - contents: {len(topic_content_match[lang][1])}')\n",
    "#     topic, content = topic_content_match[lang]\n",
    "#     topic, content = prepare_match_features(topic, content, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938fd06-20e7-4575-a5e2-5444486a1525",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calc Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "733362a1-5df4-4895-8063-92e17141245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "CPT_PATH = PATH.model_cpt\n",
    "MODEL_PATH = PATH.model\n",
    "OUTPUT_PATH = os.path.join(PATH.cv_dir, f\"fold_{CFG.fold}\")\n",
    "N_NEIGHBOR = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "468cf7f2-a99f-424c-9e38-69d436c58d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, label_name=\"\") -> None:\n",
    "        super().__init__()\n",
    "        self.data = df[label_name].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[index]\n",
    "        inputs = self.tokenizer(\n",
    "                text, \n",
    "                add_special_tokens = True,\n",
    "                truncation='longest_first',\n",
    "                max_length = 64,\n",
    "                padding = 'max_length',\n",
    "                return_attention_mask = True,\n",
    "                return_tensors = 'pt',\n",
    "        )\n",
    "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "        return inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d92794b6-f21c-470f-b665-fe2218beb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convert2Embed(object):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "        self.model = AutoModel.from_pretrained(CPT_PATH).cuda()\n",
    "\n",
    "    def convert2embeddind(self, df, label_name=\"\"):\n",
    "        embed: list = []\n",
    "        dataset = PlainDataset(df, tokenizer=self.tokenizer, label_name=label_name)\n",
    "        dataloader = DataLoader(dataset, sampler=SequentialSampler(dataset), batch_size=32)\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.cuda() for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                embeddings = self.model(**batch, output_hidden_states=True, return_dict=True).pooler_output\n",
    "                embed.append(embeddings.cpu().clone().detach().numpy())\n",
    "        embed = np.concatenate(embed, axis=0)\n",
    "        return embed\n",
    "\n",
    "    def get_embed(self):\n",
    "        for lang in topic_content_match.keys():\n",
    "            # topic, content = topic_content_match[lang]\n",
    "            # topic, content = prepare_match_features(topic, content, PATH)\n",
    "            # topic_path = os.path.join(OUTPUT_PATH, \"valid\", f\"topic_{lang}.pqt\")\n",
    "            # content_path = os.path.join(OUTPUT_PATH, \"valid\", f\"content_{lang}.pqt\")\n",
    "            # topic.to_parquet(topic_path)\n",
    "            # content.to_parquet(content_path)\n",
    "            \n",
    "            for t in [\"content\", \"topic\"]:\n",
    "                path = os.path.join(OUTPUT_PATH, \"valid\", f\"{t}_{lang}.pqt\")\n",
    "                df = pd.read_parquet(path)\n",
    "                embed = self.convert2embeddind(df, label_name=f\"field\")\n",
    "                np.save(path.replace(\".pqt\", \".npy\"), embed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f04215-9027-4408-9deb-45df9f232abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f08b9ef-56fe-44bd-8f61-1f54f6d51c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid():\n",
    "#     with open(os.path.join(OUTPUT_PATH, \"valid\", \"language.txt\"), \"r\") as f:\n",
    "#         valid_language = f.read().splitlines()\n",
    "    recall_amount = 0\n",
    "    recall_amount_total = 0\n",
    "    recall_num = 0\n",
    "    recall_total = {}\n",
    "    f2_sum = 0\n",
    "    df_list = []\n",
    "    global df_pred_all\n",
    "    for lang in topic_content_match.keys():\n",
    "        ## debug\n",
    "        # global df_pred, df_correlations\n",
    "        global df_pred\n",
    "        content_path = os.path.join(OUTPUT_PATH, \"valid\", f\"content_{lang}.npy\")\n",
    "        topics_path = os.path.join(OUTPUT_PATH, \"valid\", f\"topic_{lang}.npy\")\n",
    "        correlations_path = PATH.submission_dir\n",
    "        content_array = np.load(content_path)\n",
    "        topics_array = np.load(topics_path)\n",
    "        model = NearestNeighbors(n_neighbors=N_NEIGHBOR, metric=\"cosine\")\n",
    "        model.fit(content_array)\n",
    "        d, r = model.kneighbors(topics_array)\n",
    "        df_content = pd.read_parquet(content_path.replace(\".npy\", \".pqt\"))\n",
    "        df_topics = pd.read_parquet(topics_path.replace(\".npy\", \".pqt\"))\n",
    "        df_correlations = pd.read_csv(correlations_path).astype({\"topic_id\": str})\n",
    "        \n",
    "        pred = {\"topic_id\": [], \"content_ids\": [], 'dists': []}\n",
    "        for i in range(len(df_topics)):\n",
    "            r_t = r[i]\n",
    "            tmp = []\n",
    "            for c in r_t:\n",
    "                content_id = df_content.iloc[c][\"id\"]\n",
    "                tmp.append(content_id)\n",
    "            topics_id = df_topics.iloc[i][\"id\"]\n",
    "            pred[\"topic_id\"].append(topics_id)\n",
    "            pred[\"content_ids\"].append(tmp)\n",
    "            pred['dists'].append(d[i])\n",
    "        \n",
    "        df_pred = pd.DataFrame(pred).astype({\"topic_id\": str})\n",
    "        \n",
    "        df_correlations['content_ids'] = df_correlations['content_ids'].apply(lambda x: list(x.split()))\n",
    "        df_pred = df_pred.merge(df_correlations, on='topic_id', how='left', suffixes=['_pred', '_true'])\n",
    "        df_pred['num'] = df_pred.apply(lambda x: len(x['content_ids_true']), axis=1)\n",
    "        df_pred['hit'] = df_pred.apply(lambda x: len(set(x['content_ids_true']).intersection(x['content_ids_pred'])), axis=1)\n",
    "        df_pred['recall'] = df_pred.apply(lambda x: x['hit'] / len(x['content_ids_true']), axis=1)\n",
    "        df_pred['precision'] = df_pred.apply(lambda x: x['hit'] / len(x['content_ids_pred']), axis=1)\n",
    "        df_pred['f2'] = 5*df_pred['precision']*df_pred['recall']/(4*df_pred['precision']+df_pred['recall'])\n",
    "        recall = df_pred['recall'].mean()\n",
    "        recall_total[lang] = recall\n",
    "        recall_num += len(df_pred)\n",
    "        recall_amount += df_pred['recall'].sum()\n",
    "        recall_amount_total += df_pred['hit'].sum()/df_pred['num'].sum() * len(df_pred)\n",
    "        f2_sum += df_pred['f2'].sum()\n",
    "        df_list.append(df_pred)\n",
    "        print(f\"{lang}: {df_pred['hit'].sum()/df_pred['num'].sum()} - f2: {df_pred['f2'].sum()/len(df_pred)}\")\n",
    "        \n",
    "    df_pred_all = pd.concat(df_list)\n",
    "    print(f\"Recall: total - {recall_amount_total/recall_num} line average - {recall_amount/recall_num} - f2 - {f2_sum/recall_num}\")\n",
    "    print(f\"----------------Details----------------\")\n",
    "    for k, v in recall_total.items():\n",
    "        print(f\"Recall for language {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d57f2c62-3a2e-437c-92f0-f25c70c4ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/autodl-nas/model/r1_13/checkpoint-9738 were not used when initializing BertModel: ['lm_head.transform.dense.weight', 'mlp.dense.bias', 'lm_head.transform.dense.bias', 'lm_head.decoder.bias', 'mlp.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.transform.LayerNorm.bias', 'lm_head.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /root/autodl-nas/model/r1_13/checkpoint-9738 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 1.59 s, total: 1min 24s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "P = Convert2Embed()\n",
    "P.get_embed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4114439-f87c-40cd-88c7-a4e5b2f715cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_by_thresh(df, thresh, n_default=1):\n",
    "    pred_by_thresh = list()\n",
    "    for i, d in enumerate(df['dists']):\n",
    "        if d<=thresh:\n",
    "            pred_by_thresh.append(df['content_ids_pred'][i])\n",
    "    if not pred_by_thresh:\n",
    "        pred_by_thresh = df['content_ids_pred'][:n_default]\n",
    "    return pred_by_thresh\n",
    "\n",
    "def calculate_f2(df_pred_all, true_label='content_ids_true', pred_label='pred_by_thresh') -> int:\n",
    "    df_pred_all['hit'] = df_pred_all.apply(lambda x: len(set(x[pred_label]).intersection(x[true_label])), axis=1)\n",
    "    df_pred_all['recall'] = df_pred_all.apply(lambda x: x['hit']/len(x[true_label]), axis=1)\n",
    "    df_pred_all['precision'] = df_pred_all.apply(lambda x: x['hit']/len(x[pred_label]), axis=1)\n",
    "    df_pred_all['f2'] = (5*df_pred_all['precision']*df_pred_all['recall']/(4*df_pred_all['precision']+df_pred_all['recall'])).fillna(0)\n",
    "    return df_pred_all['f2'].mean()\n",
    "\n",
    "def optimize_f2(df_pred_all, init_thresh=0.2, init_step=0.01) -> int:\n",
    "    thresh = init_thresh\n",
    "    df_pred_all['pred_by_thresh'] = df_pred_all.apply(lambda x: get_pred_by_thresh(x, 0.2), axis=1)\n",
    "    f2 = calculate_f2(df_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa279c14-960f-4f13-af11-c30671b1a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 275 383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66ae30f5-7082-46dc-98f2-f0ce7ecc6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred_all['pred_by_thresh'] = df_pred_all.apply(lambda x: get_pred_by_thresh(x, 0.4), axis=1)\n",
    "# print(calculate_f2(df_pred_all))\n",
    "\n",
    "# df_pred_all = df_pred_all[['topic_id', 'content_ids_pred', 'dists', 'content_ids_true']]\n",
    "# # df_pred_all['labels'] = df_pred_all.apply(lambda x: label_pred(x), axis=1)\n",
    "# for i in range(170, 450, 2):\n",
    "#     thresh = i/1000\n",
    "#     df_pred_all['pred_by_thresh'] = df_pred_all.apply(lambda x: get_pred_by_thresh(x, thresh, 3), axis=1)\n",
    "#     f2 = calculate_f2(df_pred_all)\n",
    "#     print(i, f2)\n",
    "\n",
    "# df_pred_all.explode(['content_ids_pred', 'dists', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029907ba-84de-42ae-ba39-b87562768b32",
   "metadata": {},
   "source": [
    "170 0.4024688386835773\n",
    "172 0.4031549520762678\n",
    "174 0.40409479083512645\n",
    "176 0.40498780130113327\n",
    "178 0.4056221467042033\n",
    "180 0.40624726560527924\n",
    "182 0.40721841030008704\n",
    "184 0.409052690435736\n",
    "186 0.41030785013923904\n",
    "188 0.4105493930238\n",
    "190 0.4121692194096475\n",
    "192 0.4132842857948191\n",
    "194 0.4144896801795744\n",
    "196 0.41615635613829677\n",
    "198 0.41766006453443766\n",
    "200 0.41965067582784593\n",
    "202 0.4202251120409235\n",
    "204 0.42037800850695833\n",
    "206 0.4214418561517112\n",
    "208 0.4235262148368645\n",
    "210 0.42532777889037154\n",
    "212 0.42699839812736545\n",
    "214 0.42848119762586157\n",
    "216 0.43026228612064904\n",
    "218 0.43200040637419174\n",
    "220 0.4332824488732244\n",
    "222 0.43483586366382354\n",
    "224 0.4367978856794664\n",
    "226 0.43781717992134717\n",
    "228 0.4391767284118734\n",
    "230 0.44009180614394006\n",
    "232 0.4417736674332854\n",
    "234 0.4430857341640051\n",
    "236 0.44381462956587736\n",
    "238 0.44525578177706604\n",
    "240 0.4471523710828244\n",
    "242 0.44870426476357084\n",
    "244 0.4497284873353738\n",
    "246 0.45163057757041214\n",
    "248 0.4530941896947352\n",
    "250 0.4548706386758581\n",
    "252 0.45620181582970554\n",
    "254 0.45695022797459456\n",
    "256 0.4576392577793879\n",
    "258 0.4577774966032547\n",
    "260 0.45801281237339675\n",
    "262 0.45868644081494886\n",
    "264 0.458481439820201\n",
    "266 0.45903038240513294\n",
    "268 0.4595054445782289\n",
    "270 0.4594602890972266\n",
    "272 0.4594325829137616\n",
    "274 0.45987696587445226\n",
    "276 0.4602119501917246\n",
    "278 0.46098732313376983\n",
    "280 0.46121830781870066\n",
    "282 0.46157880182145566\n",
    "284 0.460916378887469\n",
    "286 0.46063599518269166\n",
    "288 0.46015462896328635\n",
    "290 0.46026819515777456\n",
    "292 0.46005084723586476\n",
    "294 0.45913039790317867\n",
    "296 0.45844901040602476\n",
    "298 0.45750240076191034\n",
    "300 0.45692206443176586\n",
    "302 0.45608328843132245\n",
    "304 0.4549603767536112\n",
    "306 0.45329443276876796\n",
    "308 0.4517214889907147\n",
    "310 0.45083376456284796\n",
    "312 0.44961959295741877\n",
    "314 0.448034045429716\n",
    "316 0.4461080456862716\n",
    "318 0.44414396537646245\n",
    "320 0.4425980612628054\n",
    "322 0.44092277734608776\n",
    "324 0.4389668410680323\n",
    "326 0.4367121022990652\n",
    "328 0.43420323722183946\n",
    "330 0.4315968321759618\n",
    "332 0.4294783204714232\n",
    "334 0.4271767339470532\n",
    "336 0.42463422374234044\n",
    "338 0.42189842384377607\n",
    "340 0.41922310125359186\n",
    "342 0.4163151008820663\n",
    "344 0.4132511312819868\n",
    "346 0.4100375863146136\n",
    "348 0.4068978474694664\n",
    "350 0.4041449159496747\n",
    "352 0.4010115542362085\n",
    "354 0.3977875787529075\n",
    "356 0.3948931385115175\n",
    "358 0.3913653717224516\n",
    "360 0.3877346850668936\n",
    "362 0.38452566672457694\n",
    "364 0.38094351006016375\n",
    "366 0.37740241893768\n",
    "368 0.3736814676972883\n",
    "370 0.36987613243759815\n",
    "372 0.36632612945386933\n",
    "374 0.36227639122395994\n",
    "376 0.35868013462650117\n",
    "378 0.35507737565132824\n",
    "380 0.3512169514101543\n",
    "382 0.3472301898209479\n",
    "384 0.343266006151315\n",
    "386 0.3389849776348872\n",
    "388 0.33505053612718283\n",
    "390 0.33077591982865007\n",
    "392 0.32659240791737504\n",
    "394 0.3223306480778996\n",
    "396 0.3180902050053218\n",
    "398 0.3139647617144388\n",
    "400 0.30977561550307586\n",
    "402 0.3056369682307033\n",
    "404 0.3015421054155209\n",
    "406 0.29711072715398107\n",
    "408 0.2929429504219797\n",
    "410 0.2888552872196978\n",
    "412 0.2845286862129868\n",
    "414 0.28014803099027047\n",
    "416 0.2759176750171542\n",
    "418 0.2719160264420336\n",
    "420 0.26765219196053575\n",
    "422 0.2634692270432641\n",
    "424 0.2592592306452557\n",
    "426 0.25531781926012703\n",
    "428 0.25119991693635824\n",
    "430 0.24713812191438406\n",
    "432 0.24296433979588497\n",
    "434 0.23907443839564776\n",
    "436 0.23522140710825673\n",
    "438 0.2312847831007713\n",
    "440 0.2273921890591881\n",
    "442 0.22357551167977419\n",
    "444 0.2195538619615006\n",
    "​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aae55ada-17dd-4be9-b840-b2fa7022824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu: 0.13582677165354332 - f2: 0.11966925839183284\n",
      "en: 0.3658066071859175 - f2: 0.3919186712598838\n",
      "es: 0.24667540737965912 - f2: 0.16398126419158054\n",
      "fr: 0.29172141918528255 - f2: 0.34113255163769163\n",
      "hi: 0.20483870967741935 - f2: 0.2021483142316011\n",
      "fil: 0.5422222222222223 - f2: 0.49821351264896346\n",
      "pt: 0.38190954773869346 - f2: 0.3659902029283047\n",
      "bn: 0.14225941422594143 - f2: 0.10952561109629172\n",
      "as: 0.14492753623188406 - f2: 0.12700563513571642\n",
      "sw: 0.1165644171779141 - f2: 0.10499548540349872\n",
      "Recall: total - 0.3227459834711503 line average - 0.42257588727041817 - f2 - 0.3168071147841835\n",
      "----------------Details----------------\n",
      "Recall for language gu: 0.15069639748225525\n",
      "Recall for language en: 0.5106737642420355\n",
      "Recall for language es: 0.2509608240772359\n",
      "Recall for language fr: 0.405689314084567\n",
      "Recall for language hi: 0.237771164021164\n",
      "Recall for language fil: 0.6928427997705106\n",
      "Recall for language pt: 0.4718885281385282\n",
      "Recall for language bn: 0.16709503411074092\n",
      "Recall for language as: 0.17543859649122806\n",
      "Recall for language sw: 0.1408251246960924\n",
      "CPU times: user 14.6 s, sys: 14.3 s, total: 28.9 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 6\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02d0ef0a-0c8c-44c1-84cb-b821e8e75ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu: 0.11614173228346457 - f2: 0.1108722993701157\n",
      "en: 0.33498111084317983 - f2: 0.3885571468838667\n",
      "es: 0.23000561902978087 - f2: 0.1675327693416328\n",
      "fr: 0.2628120893561104 - f2: 0.3277426884341225\n",
      "hi: 0.1774193548387097 - f2: 0.18345470800212874\n",
      "fil: 0.52 - f2: 0.5179257588896142\n",
      "pt: 0.35678391959798994 - f2: 0.36596929019995544\n",
      "bn: 0.12761506276150628 - f2: 0.10735863479874244\n",
      "as: 0.14492753623188406 - f2: 0.1357241327942252\n",
      "sw: 0.09815950920245399 - f2: 0.09141621492364496\n",
      "Recall: total - 0.2965139253290117 line average - 0.3976897902244021 - f2 - 0.3150750394395113\n",
      "----------------Details----------------\n",
      "Recall for language gu: 0.13392482478460782\n",
      "Recall for language en: 0.4800535200680752\n",
      "Recall for language es: 0.23902816934166288\n",
      "Recall for language fr: 0.37369914135652016\n",
      "Recall for language hi: 0.20570406445406447\n",
      "Recall for language fil: 0.6710413080895008\n",
      "Recall for language pt: 0.4516243259664313\n",
      "Recall for language bn: 0.15274472473425355\n",
      "Recall for language as: 0.17543859649122806\n",
      "Recall for language sw: 0.117886056595734\n",
      "CPU times: user 13.6 s, sys: 13.5 s, total: 27.1 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 5\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55467b6b-1272-4d99-861d-8f4903f051f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu: 0.18110236220472442 - f2: 0.12461782405585814\n",
      "en: 0.45137046861184793 - f2: 0.3788072441053249\n",
      "es: 0.30230380221015174 - f2: 0.15236436008049092\n",
      "fr: 0.36136662286465177 - f2: 0.3416748853066222\n",
      "hi: 0.2564516129032258 - f2: 0.20835327388740452\n",
      "fil: 0.6133333333333333 - f2: 0.43246466854956545\n",
      "pt: 0.44221105527638194 - f2: 0.35114859783866736\n",
      "bn: 0.16736401673640167 - f2: 0.09958438600261821\n",
      "as: 0.2608695652173913 - f2: 0.17334751853675703\n",
      "sw: 0.17177914110429449 - f2: 0.12809894234277586\n",
      "Recall: total - 0.3972581053379692 line average - 0.48782840780643766 - f2 - 0.30465557136961435\n",
      "----------------Details----------------\n",
      "Recall for language gu: 0.18263597926112993\n",
      "Recall for language en: 0.5892591211340802\n",
      "Recall for language es: 0.28967090660601086\n",
      "Recall for language fr: 0.46774943251723433\n",
      "Recall for language hi: 0.2892824250912486\n",
      "Recall for language fil: 0.7631812966150315\n",
      "Recall for language pt: 0.5320184932027038\n",
      "Recall for language bn: 0.19187688402348088\n",
      "Recall for language as: 0.2943957115009746\n",
      "Recall for language sw: 0.19726017709888677\n",
      "CPU times: user 16.2 s, sys: 14 s, total: 30.2 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 10\n",
    "valid() # Recall: total - 0.49870318143289205 line average - 0.5800252324028706 - f2 - 0.3687912849848095\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4828ea18-f47e-4442-82aa-1bdd9b403e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu: 0.22244094488188976 - f2: 0.11064560969141123\n",
      "en: 0.5617313720761996 - f2: 0.32037751832679573\n",
      "es: 0.37628769432477993 - f2: 0.1232934550448457\n",
      "fr: 0.4704336399474376 - f2: 0.3131679522449647\n",
      "hi: 0.3467741935483871 - f2: 0.20149420203731702\n",
      "fil: 0.6622222222222223 - f2: 0.29587321981900294\n",
      "pt: 0.5100502512562815 - f2: 0.295590830952673\n",
      "bn: 0.22384937238493724 - f2: 0.08752327878636781\n",
      "as: 0.37681159420289856 - f2: 0.16529631633798297\n",
      "sw: 0.22085889570552147 - f2: 0.11786997724497723\n",
      "Recall: total - 0.49419571020184905 line average - 0.5652046442179235 - f2 - 0.2564486935734837\n",
      "----------------Details----------------\n",
      "Recall for language gu: 0.2205070564451842\n",
      "Recall for language en: 0.6823018792684383\n",
      "Recall for language es: 0.3346764812169921\n",
      "Recall for language fr: 0.5415687223685159\n",
      "Recall for language hi: 0.38228698044874515\n",
      "Recall for language fil: 0.7846528973034999\n",
      "Recall for language pt: 0.588352035391509\n",
      "Recall for language bn: 0.25287164842138665\n",
      "Recall for language as: 0.3820175438596491\n",
      "Recall for language sw: 0.25444242137790524\n",
      "CPU times: user 21.1 s, sys: 15.1 s, total: 36.2 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 20\n",
    "valid() # Recall: total - 0.6107718178846423 line average - 0.6663599709233686 - f2 - 0.3068963565307041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e994d-cc6f-4343-9444-fd0a27cf998c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c004a5f-6bf1-4cb1-b2b9-95f758935e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu: 0.31299212598425197 - f2: 0.08589057552610163\n",
      "en: 0.6924282613937787 - f2: 0.2128634386408154\n",
      "es: 0.47874133732908786 - f2: 0.08313422904622883\n",
      "fr: 0.59526938239159 - f2: 0.23554027319602194\n",
      "hi: 0.4532258064516129 - f2: 0.1461030266808471\n",
      "fil: 0.8355555555555556 - f2: 0.17918331731701276\n",
      "pt: 0.5954773869346733 - f2: 0.20127385663394282\n",
      "bn: 0.34518828451882844 - f2: 0.06622440610841619\n",
      "as: 0.6086956521739131 - f2: 0.15822316465005876\n",
      "sw: 0.37423312883435583 - f2: 0.11490463474931141\n",
      "Recall: total - 0.616482377429802 line average - 0.6631366583259692 - f2 - 0.17175840061055478\n",
      "----------------Details----------------\n",
      "Recall for language gu: 0.2966699509588219\n",
      "Recall for language en: 0.7841729773022118\n",
      "Recall for language es: 0.42370964750662\n",
      "Recall for language fr: 0.641633774420152\n",
      "Recall for language hi: 0.48244150185326656\n",
      "Recall for language fil: 0.8824727481353989\n",
      "Recall for language pt: 0.6499800637958532\n",
      "Recall for language bn: 0.34647786768205624\n",
      "Recall for language as: 0.6386452241715399\n",
      "Recall for language sw: 0.39671681365229755\n",
      "CPU times: user 34.6 s, sys: 15.1 s, total: 49.7 s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 50\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50cde0c9-1d89-4aa9-adf1-6c29c4bcecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu: 0.3838582677165354 - f2: 0.06167456579286359\n",
      "en: 0.7810465396672294 - f2: 0.13946628340349818\n",
      "es: 0.5583442592245739 - f2: 0.05573199637761451\n",
      "fr: 0.6885676741130092 - f2: 0.1692763514264554\n",
      "hi: 0.535483870967742 - f2: 0.10042036444613164\n",
      "fil: 0.9111111111111111 - f2: 0.10822716173038485\n",
      "pt: 0.6582914572864321 - f2: 0.13413946372102253\n",
      "bn: 0.4393305439330544 - f2: 0.046863186496774435\n",
      "as: 0.8840579710144928 - f2: 0.1317272608638015\n",
      "sw: 0.5214723926380368 - f2: 0.09768715558465284\n",
      "Recall: total - 0.7027980985551304 line average - 0.7326370925224693 - f2 - 0.11337755570937746\n",
      "----------------Details----------------\n",
      "Recall for language gu: 0.3715427244957177\n",
      "Recall for language en: 0.8462934159186151\n",
      "Recall for language es: 0.5079205998340828\n",
      "Recall for language fr: 0.7344904850838803\n",
      "Recall for language hi: 0.5611461266544386\n",
      "Recall for language fil: 0.943631669535284\n",
      "Recall for language pt: 0.7006071048834205\n",
      "Recall for language bn: 0.4111772171981596\n",
      "Recall for language as: 0.8907407407407406\n",
      "Recall for language sw: 0.5532215991893412\n",
      "CPU times: user 57.7 s, sys: 15.9 s, total: 1min 13s\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 100\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b6c6674-9d0d-4cd1-bc71-f81fa2cd014f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu: 0.45866141732283466 - f2: 0.040237891384655645\n",
      "en: 0.8550357688288722 - f2: 0.08462437563424251\n",
      "es: 0.6486233377036899 - f2: 0.03528622085094099\n",
      "fr: 0.7700394218134035 - f2: 0.10921526732968498\n",
      "hi: 0.6080645161290322 - f2: 0.06295383842076561\n",
      "fil: 0.9644444444444444 - f2: 0.0608427832418007\n",
      "pt: 0.7462311557788944 - f2: 0.08523448395486598\n",
      "bn: 0.5418410041841004 - f2: 0.031034916642755945\n",
      "as: 0.9855072463768116 - f2: 0.08235975052351248\n",
      "sw: 0.6809815950920245 - f2: 0.07194327263229684\n",
      "Recall: total - 0.7821080813653752 line average - 0.8032735671638902 - f2 - 0.06944216324792452\n",
      "----------------Details----------------\n",
      "Recall for language gu: 0.45040878277117735\n",
      "Recall for language en: 0.9013983612722337\n",
      "Recall for language es: 0.616537514775718\n",
      "Recall for language fr: 0.8061895722938034\n",
      "Recall for language hi: 0.6269500017837613\n",
      "Recall for language fil: 0.9759036144578314\n",
      "Recall for language pt: 0.7775504101161995\n",
      "Recall for language bn: 0.4842971600825004\n",
      "Recall for language as: 0.9888888888888889\n",
      "Recall for language sw: 0.6718898485027516\n",
      "CPU times: user 1min 44s, sys: 16.3 s, total: 2min\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "N_NEIGHBOR = 200\n",
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d97fe-c8e3-409d-8d08-7f77201ef940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f8d6cc0-3a57-4dae-b7e8-33e40c87959e",
   "metadata": {},
   "source": [
    "shuffle?\n",
    "\n",
    "groupby lang shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a701ad5-deed-4cad-815c-2cbf3b57ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          375Gi        56Gi        13Gi       1.2Gi       306Gi       315Gi\n",
      "Swap:            0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "49d58c51-4c94-401f-8546-4a7a2a3eeea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "3.2G\t/root/.local/share/Trash\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610ea9f-5532-4bca-af7e-15d5a8bc2240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
